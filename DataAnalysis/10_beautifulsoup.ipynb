{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5ea18f",
   "metadata": {},
   "source": [
    "## 10. Beautiful Soup\n",
    "- HTML과 XML 파일에서 데이터를 추출하기 위한 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4561fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f270fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "  <title>\n",
      "   크롤링 연습 페이지\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1 class=\"title\">\n",
      "   Hello BeautifulSoup\n",
      "  </h1>\n",
      "  <h1 class=\"sub_title\">\n",
      "   안녕! 아름다운 수프\n",
      "  </h1>\n",
      "  <p id=\"description\">\n",
      "   이 페이지는 BeautifulSoup 학습을 위한 예제입니다.\n",
      "  </p>\n",
      "  <ul class=\"items\">\n",
      "   <li>\n",
      "    사과\n",
      "   </li>\n",
      "   <li>\n",
      "    바나나\n",
      "   </li>\n",
      "   <li>\n",
      "    체리\n",
      "   </li>\n",
      "  </ul>\n",
      "  <ul class=\"items\">\n",
      "   <li>\n",
      "    Python\n",
      "   </li>\n",
      "   <li>\n",
      "    C++\n",
      "   </li>\n",
      "   <li>\n",
      "    SQL\n",
      "   </li>\n",
      "  </ul>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "  html_data = f.read()\n",
    "  \n",
    "# soup 객체 생성\n",
    "# soup = BeautifulSoup(html_data, \"html.parser\") # 내장 파서\n",
    "soup = BeautifulSoup(html_data, \"lxml\") # xml 일때 사용, 설치 필요\n",
    "# print(soup)\n",
    "print(soup.prettify()) # 들여쓰기 표시\n",
    "\n",
    "# 파서 차이 비교\n",
    "# print(BeautifulSoup(\"<a></p>\", \"html.parser\")) # <a></a>\n",
    "\n",
    "# print(BeautifulSoup(\"<a></p>\", \"lxml\")) # <html><body><a></a></body></html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44770e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"title\">Hello BeautifulSoup</h1>\n",
      "Hello BeautifulSoup\n",
      "Hello BeautifulSoup\n"
     ]
    }
   ],
   "source": [
    "# 데이터 선택\n",
    "# find() - 첫번째 매칭 요소 선택\n",
    "# 1) 태그를 기준으로 탐색\n",
    "title_tag = soup.find(\"h1\")\n",
    "print(title_tag)\n",
    "print(title_tag.text)\n",
    "print(title_tag.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41d1bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕! 아름다운 수프\n"
     ]
    }
   ],
   "source": [
    "# find() - 속성 조건으로 검색 가능\n",
    "result = soup.find(\"h1\", class_=\"sub_title\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65d5a734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 class=\"title\">Hello BeautifulSoup</h1>, <h1 class=\"sub_title\">안녕! 아름다운 수프</h1>]\n",
      "Hello BeautifulSoup\n",
      "안녕! 아름다운 수프\n"
     ]
    }
   ],
   "source": [
    "# find_all() - 모든 매칭된 요소 선택\n",
    "result = soup.find_all(\"h1\")\n",
    "print(result)\n",
    "\n",
    "for i in result:\n",
    "  print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2e0ce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"items\">\n",
      "<li>사과</li>\n",
      "<li>바나나</li>\n",
      "<li>체리</li>\n",
      "</ul>, <ul class=\"items\">\n",
      "<li>Python</li>\n",
      "<li>C++</li>\n",
      "<li>SQL</li>\n",
      "</ul>]\n",
      "\n",
      "사과\n",
      "바나나\n",
      "체리\n",
      "\n",
      "\n",
      "Python\n",
      "C++\n",
      "SQL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select() - 모든 매칭 요소 선택\n",
    "# CSS 선택자로 탐색\n",
    "result = soup.select(\"ul.items\")\n",
    "print(result)\n",
    "\n",
    "for i in result:\n",
    "  print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef4b6ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul class=\"items\">\n",
       "<li>사과</li>\n",
       "<li>바나나</li>\n",
       "<li>체리</li>\n",
       "</ul>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select_one() - 첫번째 매칭 요소 선택\n",
    "result = soup.select_one(\"ul.items\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e1eaa1",
   "metadata": {},
   "source": [
    "### Requests\n",
    "- HTTP 프로토콜을 이용하여 웹 사이트로부터 데이터를 송수신 하는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38fdae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Good Goodbye\n",
      "2. ONE MORE TIME\n",
      "3. 타임캡슐\n",
      "4. Blue Valentine\n",
      "5. SPAGHETTI (feat. j-hope of BTS)\n",
      "6. Golden\n",
      "7. Drowning\n",
      "8. 멸종위기사랑\n",
      "9. 첫 눈\n",
      "10. 달리 표현할 수 없어요\n"
     ]
    }
   ],
   "source": [
    "# beautifulsoup & requests 함께 이용\n",
    "# 멜론에서 Top10의 노래 제목을 받아오기\n",
    "\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "headers = {\n",
    "  \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# print(response.status_code) # 200: 성공, 404: 페이지 없음, 500: 서버 에러\n",
    "# print(response.text)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "songs = soup.select(\"div.ellipsis.rank01 a\")[:10]\n",
    "\n",
    "for idx, song in enumerate(songs):\n",
    "  print(f\"{idx+1}. {song.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc6f9bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 오늘의 뉴스 ==\n",
      "HD현대스포츠, '대한민국 스포츠산업대상' 수상... 최우수상은 KT스포츠 / 링크: https://www.starnewskorea.com/sports/2025/12/11/2025121108405175271\n",
      "\"박진만 감독 현역 시절 생각나\" 고3 유격수 곧바로 1군 경쟁 돌입, 박찬... / 링크: https://www.starnewskorea.com/sports/2025/12/11/2025121118324144888\n",
      "외야 골든글러브 수상한 kt 위즈 안현민 / 링크: https://www.newsis.com/view/NISI20251209_0021090910\n",
      "“꿈만 같다” 한국야구 히트상품 떠오른 KT 안현민, 13년 만에 신인상... / 링크: https://sports.donga.com/sports/article/all/20251209/132933828/1\n"
     ]
    }
   ],
   "source": [
    "# 실습2. 사용자로부터 입력을 받아 크롤링\n",
    "\n",
    "word = input(\"검색어를 입력하세요.\")\n",
    "\n",
    "headers = {\n",
    "  \"User-Agent\" : \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "response = requests.get(f\"https://search.naver.com/search.naver?query={word}\", headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "# print(soup.prettify())\n",
    "news_list = soup.select(\"a.fender-ui_228e3bd1.moM44hE6Je7O8nL1iBI9\")\n",
    "\n",
    "print(\"== 오늘의 뉴스 ==\")\n",
    "# print(news_list)\n",
    "\n",
    "for a in news_list:\n",
    "  print(f\"{a.get_text()} / 링크: {a.get(\"href\")}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580339e3",
   "metadata": {},
   "source": [
    "### openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "787a45c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링한 자료를 엑셀로 저장\n",
    "import openpyxl\n",
    "\n",
    "# 엑셀 파일 만들기\n",
    "wb = openpyxl.Workbook()\n",
    "\n",
    "# 시트 만들기\n",
    "ws = wb.create_sheet(\"test\")\n",
    "\n",
    "ws[\"A1\"] = \"이름\"\n",
    "ws[\"B1\"] = \"나이\"\n",
    "\n",
    "ws[\"A2\"] = \"홍길동\"\n",
    "ws[\"B2\"] = 30\n",
    "\n",
    "wb.save(\"test.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de13b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "wb = openpyxl.load_workbook(\"test.xlsx\")\n",
    "\n",
    "# 시트 선택\n",
    "ws = wb[\"test\"]\n",
    "\n",
    "# 여러 자료 추가\n",
    "data = [\n",
    "  [\"kim\", 20],\n",
    "  [\"lee\", 14],\n",
    "  [\"park\", 34]\n",
    "]\n",
    "\n",
    "for row in data:\n",
    "  ws.append(row)\n",
    "  \n",
    "wb.save(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습3.\n",
    "\n",
    "wb = openpyxl.load_workbook(\"test.xlsx\")\n",
    "\n",
    "# 시트 선택\n",
    "ws = wb[\"test\"]\n",
    "\n",
    "res  = requests.get(\"https://finance.naver.com/marketindex/\")\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "result = soup.select(\"div.market1 a.head\")\n",
    "\n",
    "# data = []\n",
    "ws.append([\"통화\", \"환율\"])\n",
    "for a in result:\n",
    "  exchange = a.select_one(\"span.blind\").get_text().split()[1] # USD\n",
    "  value = a.select_one(\"span.value\").get_text()\n",
    "  # data.append([exchange, value]) # df 이용 저장 (to_excel)\n",
    "  ws.append([exchange, value])\n",
    "\n",
    "  \n",
    "wb.save(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98fb49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
